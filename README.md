# data-extraction

# Introduction

Close to 90% of all information is unstructured. Normal methodologies of looking through large collection are full content inquiry and metadata search which aren't efficient. Hence, to overcome this issue a computerised smart framework is required which helps in extracting all the possible keywords in the text. We will be focusing on three major types: Geographical, Resume and Unstructured Data.

# Scope

In order to cater to the needs of the market and the users. I have worked on a software which allows the user to enter their document from which they need to extract keywords of either type may it be Geographical Locations, Resume or Unstructured Data. The software then runs a couple of Natural Language Processing techniques like Tokenization, Parts of Speech & Lemmatization etc, and a few Machine Learning techniques like Numpy, SpaCy which in turn provides the users with the desired output in their respective
